{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, requests\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd().replace('/src', ''), 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebScraping Player Game Log Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASON_DATES = {\n",
    "    '2020-21': ['20201222', '20210516'],\n",
    "    '2021-22': ['20211017', '20220410'],\n",
    "    '2022-23': ['20221018', '20230206'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataScraper():\n",
    "    # Scraping Historical Game Data from Basketball-Reference.com\n",
    "    def get_boxscores(self, season, date_list):\n",
    "        url_parent = \"https://www.basketball-reference.com\"\n",
    "        url_boxscore = \"https://www.basketball-reference.com/boxscores/?month={month}&day={day}&year={year}\"\n",
    "\n",
    "        print(\"Scraping boxscores from the {} regular season\".format(season))\n",
    "        \n",
    "        for date in tqdm(date_list):\n",
    "            # BeautifulSoup object for a list of boxscores on a given day\n",
    "            url_summaries = url_boxscore.format(month=date[4:6],day=date[6:8],year=date[0:4])\n",
    "            soup_summaries = BeautifulSoup(urlopen(url_summaries),'lxml')\n",
    "            games = soup_summaries.find_all('div',class_='game_summary expanded nohover')\n",
    "\n",
    "            for game in games:\n",
    "                summary = {}\n",
    "\n",
    "                host = game.find_all('table')[1].find_all('a')[1]['href'][7:10]\n",
    "\n",
    "                winner = game.find('tr',class_='winner').find_all('td')\n",
    "                loser = game.find('tr',class_='loser').find_all('td')\n",
    "\n",
    "                summary['winner'] = [winner[0].find('a')['href'][7:10],int(winner[1].get_text())]\n",
    "                summary['loser'] = [loser[0].find('a')['href'][7:10],int(loser[1].get_text())]\n",
    "\n",
    "\n",
    "                url_game = url_parent+game.find('a',text='Box Score')['href']\n",
    "                soup_game = BeautifulSoup(urlopen(url_game),'lxml')\n",
    "\n",
    "\n",
    "                tables = soup_game.find_all('table',limit=4)[2:]\n",
    "\n",
    "                columns_basic = [th.get_text() for th in tables[0].find('thead').find_all('tr')[1].find_all('th')][1:]\n",
    "                columns_advanced = [th.get_text() for th in tables[1].find('thead').find_all('tr')[1].find_all('th')][2:]\n",
    "\n",
    "                column_headers = ['Name','Date','Team','Home','W','W_PTS','L','L_PTS','MP','FG','FGA','FG_perc','3P','3PA','3P_perc','FT'\n",
    "                                ,'FT_perc','ORB','DRB','TRB','AST','STL','BLK','TOV','PF','PTS','+-','TS_perc','eFG_perc','3PAr','FTA'\n",
    "                                ,'FTr','ORB_perc','DRB_perc','TRB_perc','AST_perc','STL_perc','BLK_perc','TOV_perc','USG_perc','ORtg','DRtg','BPM']\n",
    "                \n",
    "                teams = ['winner','loser']\n",
    "                basic_stat_template = 'box-{team}-game-basic'\n",
    "                advanced_stat_template = 'box-{team}-game-advanced'\n",
    "\n",
    "                for team in teams:\n",
    "                    if summary[team][0] == host:\n",
    "                        home = 1\n",
    "                    else:\n",
    "                        home = 0\n",
    "\n",
    "                    basic_stat = basic_stat_template.format(team=summary[team][0].upper())\n",
    "                    advanced_stat = advanced_stat_template.format(team=summary[team][0].upper())\n",
    "\n",
    "                    game_data = [date, summary[team][0], home,summary['winner'][0],\n",
    "                                 summary['winner'][1], summary['loser'][0],summary['loser'][1]]\n",
    "                    \n",
    "                    data_basic = soup_game.find('table',id=basic_stat).find('tbody').find_all('tr',class_=None)\n",
    "                    data_advanced = soup_game.find('table',id=advanced_stat).find('tbody').find_all('tr',class_=None)\n",
    "\n",
    "                    n = len(data_basic)\n",
    "\n",
    "                    player_names = [data_basic[i].find('a').get_text() for i in range(n)]\n",
    "\n",
    "                    player_data = []\n",
    "                    injury_keywords = ['Did Not Play', 'Not With Team']\n",
    "\n",
    "                    for i in range(n):\n",
    "                        if data_basic[i].find('td').get_text() not in injury_keywords:\n",
    "                            data = [player_names[i]] + game_data + \\\n",
    "                                   [td.get_text() for td in data_basic[i].find_all('td')] + \\\n",
    "                                   [td.get_text() for td in data_advanced[i].find_all('td')[1:]]\n",
    "\n",
    "                            player_data.append(data)\n",
    "                    df = pd.DataFrame(player_data,columns=column_headers)\n",
    "#                     df.columns = df.columns.str.replace('%','_perc').str.replace('/','')\n",
    "                    df = df.fillna(0)\n",
    "                    df.loc[:,'FG':'+-'] = df.loc[:,'FG':'+-'].apply(pd.to_numeric)\n",
    "                    df['MP'] = [0.00 if ':' not in t else round(int(t.split(':')[0])+int(t.split(':')[1])/60, 2) for t in df['MP']] \n",
    "                    df.to_csv(os.path.join(*[DATA_DIR, 'Boxscores', season, date+'-'+summary[team][0]+'.csv']), index=False)\n",
    "\n",
    "                time.sleep(10)\n",
    "        return None\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping boxscores from the 2020-21 regular season\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111c2e99e2e54aaf87cc74a40a0bb67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping boxscores from the 2021-22 regular season\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0c1c2f8f7947699c2c6b7e662aef06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping boxscores from the 2022-23 regular season\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d7abd8eaf64000b856aba12a1b583e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scraper = DataScraper()\n",
    "\n",
    "# Comment out season dates in SEASON_DATES in constants.py to extract data for specific seasons\n",
    "for data_type in ['Boxscores']:\n",
    "    for season in SEASON_DATES.keys(): \n",
    "        if not os.path.exists(os.path.join(DATA_DIR, data_type, season)):\n",
    "            # Create a new directory and scrape the entire season\n",
    "            os.makedirs(os.path.join(DATA_DIR, data_type, season))\n",
    "            start_date = SEASON_DATES[season][0]\n",
    "            end_date = SEASON_DATES[season][1]\n",
    "            date_list = [d.strftime('%Y%m%d') for d in pd.date_range(start_date, end_date)]\n",
    "\n",
    "            if data_type == 'Boxscores':\n",
    "                scraper.get_boxscores(season, date_list)\n",
    "            else:\n",
    "                scraper.get_fantasy_salary(season, date_list)\n",
    "\n",
    "\n",
    "        elif os.path.exists(os.path.join(DATA_DIR, data_type, season)):\n",
    "            # Iterate over the existing files by name and scrape missing dates\n",
    "            start_date = SEASON_DATES[season][0]\n",
    "            end_date = SEASON_DATES[season][1]\n",
    "            # Dates to scrape box scores from\n",
    "            date_list = [d.strftime('%Y%m%d') for d in pd.date_range(start_date, end_date)]\n",
    "                            \n",
    "            if data_type == 'Boxscores':               \n",
    "                for date in date_list:\n",
    "                    # Check if csv files of the form {date}-{hometeam}.csv (i.e. 20131029-CHI.csv) exists\n",
    "                    if len(glob.glob(os.path.join(DATA_DIR, data_type, season, str(date)+\"*.csv\"))) > 0:\n",
    "                        # Set back the start day by \n",
    "                        date_list = date_list[date_list.index(date):]\n",
    "\n",
    "                scraper.get_boxscores(season, date_list)\n",
    "                \n",
    "            else:\n",
    "                for date in date_list:\n",
    "                    # Check if csv files of the form salary_{date}.csv (i.e. salary_20131029.csv) exists\n",
    "                    if os.path.exists(os.path.join(DATA_DIR, data_type, season, \"salary_{}.csv\".format(date))):\n",
    "                        date_list = date_list[date_list.index(date):]\n",
    "                scraper.get_fantasy_salary(season, date_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebScraping Team Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_list = ['NBA_2021.html', 'NBA_2022.html', 'NBA_2023.html']\n",
    "def get_table(Season, url='https://www.basketball-reference.com/leagues/'):\n",
    "    Season_url = f'{url}/{Season}'\n",
    "    page = requests.get(Season_url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    table = soup.find(\"table\", attrs={\"id\":\"advanced-team\"})\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    return df\n",
    "\n",
    "for season in season_list:\n",
    "    data = get_table(Season)\n",
    "    data.to_csv('C:\\\\Users\\\\12242\\\\103122\\\\NBA-Fantasy-Point-Projections\\\\data\\\\Team Stats\\\\'f'Team_Stats_{Season}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
