{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RepeatedKFold\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the Dataframe I prepared in Notebook 02, Data Preparation\n",
    "df = pd.read_csv('C:\\\\Users\\\\12242\\\\103122\\\\NBA-Fantasy-Point-Projections\\\\data\\\\Prepared_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date', 'FPTS/M', 'FPTS_Shtng'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 61921 entries, 0 to 62569\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Name        61921 non-null  object \n",
      " 1   Team        61921 non-null  object \n",
      " 2   Home        61921 non-null  int64  \n",
      " 3   Spread      61921 non-null  int64  \n",
      " 4   MP          61921 non-null  float64\n",
      " 5   USG_perc    61921 non-null  float64\n",
      " 6   FPTS        61921 non-null  float64\n",
      " 7   PTS         61921 non-null  int64  \n",
      " 8   Opp         61921 non-null  object \n",
      " 9   FPTS/M      61921 non-null  float64\n",
      " 10  FPTS_Shtng  61921 non-null  float64\n",
      " 11  Pace        61921 non-null  float64\n",
      " 12  ORtg        61921 non-null  float64\n",
      " 13  DRtg        61921 non-null  float64\n",
      " 14  Off_eFG%    61921 non-null  float64\n",
      " 15  DEF_eFG%    61921 non-null  float64\n",
      " 16  Opp_pace    61921 non-null  float64\n",
      " 17  Opp_DRtg    61921 non-null  float64\n",
      "dtypes: float64(12), int64(3), object(3)\n",
      "memory usage: 9.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_new = df[(np.abs(stats.zscore(df['FPTS'])) < 3)]\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12242\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df_new.drop(['FPTS/M', 'FPTS_Shtng'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 61921 entries, 0 to 62569\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Name      61921 non-null  object \n",
      " 1   Team      61921 non-null  object \n",
      " 2   Home      61921 non-null  int64  \n",
      " 3   Spread    61921 non-null  int64  \n",
      " 4   MP        61921 non-null  float64\n",
      " 5   USG_perc  61921 non-null  float64\n",
      " 6   FPTS      61921 non-null  float64\n",
      " 7   PTS       61921 non-null  int64  \n",
      " 8   Opp       61921 non-null  object \n",
      " 9   Pace      61921 non-null  float64\n",
      " 10  ORtg      61921 non-null  float64\n",
      " 11  DRtg      61921 non-null  float64\n",
      " 12  Off_eFG%  61921 non-null  float64\n",
      " 13  DEF_eFG%  61921 non-null  float64\n",
      " 14  Opp_pace  61921 non-null  float64\n",
      " 15  Opp_DRtg  61921 non-null  float64\n",
      "dtypes: float64(10), int64(3), object(3)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_new['FPTS']\n",
    "X = df_new.drop(['FPTS', 'DEF_eFG%', 'DRtg'], axis=1)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating The pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Spread','MP','USG_perc','Pace','Opp_pace','Opp_DRtg']\n",
    "categorical_features = ['Name','Team', 'Opp', 'Home']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pipeline Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode all Categorical Features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all the Numeric Features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the two pipelines together\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Simple Models\n",
    "Using 3 different simple models to get baseline estimates\n",
    "- Dummy regressor using median \n",
    "- Dummy Regressor using mean\n",
    "- Linear regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_median = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('reg_median', DummyRegressor(strategy = 'median'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_mean = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('reg_mean', DummyRegressor(strategy = 'mean'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('lr', LinearRegression(normalize=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('ridge', Ridge(normalize=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the training data to pipeline models\n",
    "dummy_median = reg_median.fit(X_train, y_train)\n",
    "dummy_mean = reg_mean.fit(X_train, y_train)\n",
    "lm = lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = lm.predict(X_test)\n",
    "y_predict_dummy_mean = dummy_mean.predict(X_test)\n",
    "y_predict_dummy_median = dummy_median.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = ridge.fit(X_train, y_train)\n",
    "y_predict_ridge = rm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error metrics to assess models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (dummy): 130.89\n",
      "Mean squared error (linear model): 60.08\n",
      "Mean squared error (ridge model): 43.08\n",
      "Mean absolute error (linear model): 5.07\n",
      "Mean absolute error (ridge model): 6.15\n",
      "Median absolute error (dummy): 7.75\n",
      "Median absolute error (linear model): 4.06\n",
      "r2_score (dummy mean): -0.00\n",
      "r2_score (dummy median): -0.02\n",
      "r2_score (linear model): 0.67\n",
      "r2_score (ridge model): 0.54\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error (dummy): {:.2f}\".format(mean_squared_error(y_test, \n",
    "                                                                     y_predict_dummy_mean)))\n",
    "print(\"Mean squared error (linear model): {:.2f}\".format(mean_squared_error(y_test, y_predict_ridge)))\n",
    "\n",
    "print(\"Mean squared error (ridge model): {:.2f}\".format(mean_squared_error(y_test, y_predict)))\n",
    "\n",
    "print(\"Mean absolute error (linear model): {:.2f}\".format(mean_absolute_error(y_test, y_predict)))\n",
    "\n",
    "print(\"Mean absolute error (ridge model): {:.2f}\".format(mean_absolute_error(y_test, y_predict_ridge)))\n",
    "\n",
    "print(\"Median absolute error (dummy): {:.2f}\".format(median_absolute_error(y_test, \n",
    "                                                                    y_predict_dummy_median)))\n",
    "print(\"Median absolute error (linear model): {:.2f}\".format(median_absolute_error(y_test, y_predict)))\n",
    "  \n",
    "print(\"r2_score (dummy mean): {:.2f}\".format(r2_score(y_test, y_predict_dummy_mean)))\n",
    "print(\"r2_score (dummy median): {:.2f}\".format(r2_score(y_test, y_predict_dummy_median)))\n",
    "print(\"r2_score (linear model): {:.2f}\".format(r2_score(y_test, y_predict)))\n",
    "print(\"r2_score (ridge model): {:.2f}\".format(r2_score(y_test, y_predict_ridge)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear regression model performed by far the best with a decent r2 score as well as a mean absolute error of about 5. While, Draftkings stock predictions have a mean absolute error closer to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65635499 0.66279356 0.66318683 0.66460632 0.65051829]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(lr, X_train, y_train, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The model is not overfit with cross val scores on training data being very close to r2 of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_poly = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('poly', PolynomialFeatures(=)),\n",
    "     ('lr', LinearRegression(normalize=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-af79bc9bde9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlm_poly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_poly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_predict_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlm_poly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1512\u001b[0m         n_samples, n_features = self._validate_data(\n\u001b[0;32m   1513\u001b[0m             X, accept_sparse=True).shape\n\u001b[1;32m-> 1514\u001b[1;33m         combinations = self._combinations(n_features, self.degree,\n\u001b[0m\u001b[0;32m   1515\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteraction_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m                                           self.include_bias)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36m_combinations\u001b[1;34m(n_features, degree, interaction_only, include_bias)\u001b[0m\n\u001b[0;32m   1454\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0minclude_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m         return chain.from_iterable(comb(range(n_features), i)\n\u001b[1;32m-> 1456\u001b[1;33m                                    for i in range(start, degree + 1))\n\u001b[0m\u001b[0;32m   1457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "lm_poly = lr_poly.fit(X_train, y_train)\n",
    "y_predict_final = lm_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-129-ecdb719a7915>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-129-ecdb719a7915>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    print(\"r2_score (linear model): {:.2f}\".format(r2_score(y_test, y_predict_final))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error (linear model): {:.2f}\".format(mean_squared_error(y_test, y_predict_final)))\n",
    "print(\"Mean absolute error (linear model): {:.2f}\".format(mean_absolute_error(y_test, y_predict_final)))\n",
    "print(\"Median absolute error (linear model): {:.2f}\".format(median_absolute_error(y_test, y_predict_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score (linear model): 0.26\n"
     ]
    }
   ],
   "source": [
    "print(\"r2_score (linear model): {:.2f}\".format(r2_score(y_test, y_predict_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Advanced Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get performance of models\n",
    "def performance(y_true, y_predict):\n",
    "    \"\"\" \n",
    "    Calculates and returns the two performance scores between \n",
    "    true and predicted values - first R-Squared, then RMSE\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the r2 score between 'y_true' and 'y_predict'\n",
    "    r2 = r2_score(y_true, y_predict)\n",
    "\n",
    "    # Calculate the root mean squared error between 'y_true' and 'y_predict'\n",
    "    rmse = mean_squared_error(y_true, y_predict, squared=False)\n",
    "\n",
    "    #Calculate the mean absolute error\n",
    "    mae = mean_absolute_error(y_true, y_predict)\n",
    "\n",
    "    \n",
    "    # Return the score\n",
    "    return [r2, rmse, mae]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Try a Decison Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_processed = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('dtr', DecisionTreeRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a Grid Search to get the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_param_grid = [{'dtr__max_depth': [4, 5, 6, 10, 20, 40, 50,], \n",
    "         'dtr__min_samples_split': [2, 5, 10, 20, 40, 50], \n",
    "         'dtr__min_samples_leaf': [1, 3, 5, 9, 15, 25, 40]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_gs = GridSearchCV(dtr_processed, dtr_param_grid, scoring='r2', cv=10)\n",
    "dtr_gs.fit(X_train, y_train)\n",
    "\n",
    "best_dtr_parameters = dtr_gs.best_params_\n",
    "\n",
    "print('Grid Search found the following optimal parameters: ')\n",
    "for param_name in sorted(rf_best_parameters.keys()):\n",
    "    print('%s: %r' % (param_name, rf_best_parameters[param_name]))\n",
    "    \n",
    "y_pred_dtr = dtr_gs.predict(X_test)\n",
    "score = performance(y_test, y_pred_dtr)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision tree model is worse than the linear regression model by both metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_processed = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('RF', RandomForestRegressor(random_state=42,max_depth=20, min_samples_leaf=1, min_samples_split=60, n_estimators=400))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once again use a Grid Search to get the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = [{ \n",
    "    'n_estimators': [200,300,400,500],\n",
    "    'max_features': ['sqrt','log2']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs = GridSearchCV(RF_processed, rf_param_grid, scoring='r2', cv=10)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "best_rf_parameters = grid_clf.best_params_\n",
    "\n",
    "print('Grid Search found the following optimal parameters: ')\n",
    "for param_name in sorted(rf_best_parameters.keys()):\n",
    "    print('%s: %r' % (param_name, rf_best_parameters[param_name]))\n",
    "\n",
    "y_pred_rf = rg_gs.predict(X_test)\n",
    "score = performance(y_test, y_pred_rf)\n",
    "print(score)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Better than the decision tree model but still not as good as the linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Try a XGB Boost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model2 = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('XGB', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Spread', 'MP', 'USG_perc',\n",
       "                                                   'Pace', 'Opp_pace',\n",
       "                                                   'Opp_DRtg']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Name', 'Team', 'Opp',\n",
       "                                                   'Home'])])),\n",
       "                ('XGB',\n",
       "                 XGBRegressor(bas...\n",
       "                              colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints='',\n",
       "                              learning_rate=0.300000012, max_delta_step=0,\n",
       "                              max_depth=6, min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=100,\n",
       "                              n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                              subsample=1, tree_method='exact',\n",
       "                              validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6419531919730985, 6.845407127683802, 5.2516704141982]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1 = XGB_model.predict(X_test)\n",
    "score = performance(y_test, y_pred_1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63554846 0.63543662 0.6375313  0.63680606 0.62442764]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(XGB_model, X_train, y_train, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Very similar to the linear regression model scores, but very slightly worse. However it is not overfit. So let's try running a grid search to find the optimal hyper parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('XGB', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_param_grid ={\n",
    "    \"XGB__learning_rate\": (0.05, 0.10, 0.15, 0.2),\n",
    "    \"XGB__max_depth\": [ 3, 6, 8],\n",
    "    \"XGB__min_child_weight\": [ 1, 3, 5],\n",
    "    \"XGB__subsample\": [0.5, 0.7],\n",
    "    \"XGB__n_estimators\": [100, 200],\n",
    "    \"XGB__gamma\":[ 0.0, 0.1, 0.2],\n",
    "    \"XGB__colsample_bytree\":[ 0.3, 0.4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search found the following optimal parameters: \n",
      "XGB__colsample_bytree: 0.4\n",
      "XGB__gamma: 0.0\n",
      "XGB__learning_rate: 0.2\n",
      "XGB__max_depth: 8\n",
      "XGB__min_child_weight: 5\n",
      "XGB__n_estimators: 200\n",
      "XGB__subsample: 0.7\n",
      "[0.6569865901997829, 6.700156221943865, 5.14442894708609]\n"
     ]
    }
   ],
   "source": [
    "XGB_gs = GridSearchCV(XGB_model, XGB_param_grid, scoring='r2', cv=5)\n",
    "XGB_gs.fit(X_train, y_train)\n",
    "\n",
    "XGB_best_parameters = XGB_gs.best_params_\n",
    "\n",
    "print('Grid Search found the following optimal parameters: ')\n",
    "for param_name in sorted(XGB_best_parameters.keys()):\n",
    "    print('%s: %r' % (param_name, XGB_best_parameters[param_name]))\n",
    "\n",
    "y_pred_XGB = XGB_gs.predict(X_test)\n",
    "score = performance(y_test, y_pred_XGB)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model_final = Pipeline([\n",
    "     ('preprocessor', preprocessor),\n",
    "     ('XGB', XGBRegressor(learning_rate=0.3, max_depth=8, min_child_weight=7, n_estimators=350, subsample=0.9))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Spread', 'MP', 'USG_perc',\n",
       "                                                   'Pace', 'Opp_pace',\n",
       "                                                   'Opp_DRtg']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Name', 'Team', 'Opp',\n",
       "                                                   'Home'])])),\n",
       "                ('XGB',\n",
       "                 XGBRegressor(bas...\n",
       "                              colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints='', learning_rate=0.3,\n",
       "                              max_delta_step=0, max_depth=8, min_child_weight=7,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=350, n_jobs=0, num_parallel_tree=1,\n",
       "                              random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                              scale_pos_weight=1, subsample=0.9,\n",
       "                              tree_method='exact', validate_parameters=1,\n",
       "                              verbosity=None))])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6479778812726678, 6.787570536183406, 5.184198102047566]\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = XGB_model_final.predict(X_test)\n",
    "score = performance(y_test, y_pred_final)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_model.pkl']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr, \"lr_model.pkl\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
